import pandas as pd
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.model_selection import train_test_split
import numpy as np

# Load dataset (you can replace this with MovieLens CSV file)
ratings = pd.read_csv("ratings.csv")  # columns: userId, movieId, rating

# Pivot user-item matrix
user_item_matrix = ratings.pivot_table(index='userId', columns='movieId', values='rating').fillna(0)
user_sim = cosine_similarity(user_item_matrix)
user_sim_df = pd.DataFrame(user_sim, index=user_item_matrix.index, columns=user_item_matrix.index)

# Function to recommend movies based on similar users
def recommend_movies_user_based(user_id, top_n=5):
    similar_users = user_sim_df[user_id].sort_values(ascending=False)[1:6]
    weighted_ratings = pd.Series(dtype=float)
    for sim_user, sim_score in similar_users.items():
        sim_user_ratings = user_item_matrix.loc[sim_user]
        weighted_ratings = weighted_ratings.add(sim_user_ratings * sim_score, fill_value=0)
    user_seen = user_item_matrix.loc[user_id][user_item_matrix.loc[user_id] > 0].index
    weighted_ratings = weighted_ratings.drop(user_seen, errors='ignore')
    return weighted_ratings.sort_values(ascending=False).head(top_n)

print("User-Based CF Recommendations for User 1:")
print(recommend_movies_user_based(1))


# Project 2: Content-Based Filtering using TF-IDF

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

movies = pd.read_csv("movie_metadata.csv")
movies = movies[['movie_title', 'genres', 'plot_keywords']].dropna()
movies['combined'] = movies['genres'] + ' ' + movies['plot_keywords']

# TF-IDF matrix
tfidf = TfidfVectorizer(stop_words='english')
tfidf_matrix = tfidf.fit_transform(movies['combined'])
cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)

# Function to recommend movies
def recommend(title):
    idx = movies[movies['movie_title'].str.strip() == title].index[0]
    sim_scores = list(enumerate(cosine_sim[idx]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:6]
    movie_indices = [i[0] for i in sim_scores]
    return movies['movie_title'].iloc[movie_indices]

print("Content-Based Recommendations for 'Avatar':")
print(recommend("Avatar"))


# Project 3: Neural Collaborative Filtering

import tensorflow as tf

user_ids = ratings['userId'].unique().tolist()
movie_ids = ratings['movieId'].unique().tolist()

user_to_index = {x: i for i, x in enumerate(user_ids)}
movie_to_index = {x: i for i, x in enumerate(movie_ids)}

ratings['user_idx'] = ratings['userId'].map(user_to_index)
ratings['movie_idx'] = ratings['movieId'].map(movie_to_index)

X = ratings[['user_idx', 'movie_idx']]
y = ratings['rating']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

num_users = len(user_ids)
num_movies = len(movie_ids)
embedding_size = 50

user_input = tf.keras.Input(shape=(1,))
movie_input = tf.keras.Input(shape=(1,))
user_embed = tf.keras.layers.Embedding(num_users, embedding_size)(user_input)
movie_embed = tf.keras.layers.Embedding(num_movies, embedding_size)(movie_input)
dot_product = tf.keras.layers.Dot(axes=2)([user_embed, movie_embed])
dot_product = tf.keras.layers.Flatten()(dot_product)

model = tf.keras.Model(inputs=[user_input, movie_input], outputs=dot_product)
model.compile(optimizer='adam', loss='mse')
model.fit([X_train['user_idx'], X_train['movie_idx']], y_train, epochs=5)

# Predict
y_pred = model.predict([X_test['user_idx'], X_test['movie_idx']])
